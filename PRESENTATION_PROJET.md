# Projet OCR Intelligent - Pr√©sentation

## üìã R√©sum√© du Projet

**Titre:** Syst√®me d'Extraction OCR Intelligent avec Post-traitement LLM

**Objectif:** D√©velopper une application Python capable d'extraire le texte de documents scann√©s (PDF, images) avec correction automatique des erreurs OCR et structuration intelligente des donn√©es en format JSON.

---

## üõ†Ô∏è Technologies et Outils Utilis√©s

### 1. **Technologies de Base**

#### **OCR (Optical Character Recognition)**
- **Tesseract OCR** : Moteur OCR open-source
  - Chemin d'installation: `C:\Program Files\Tesseract-OCR\tesseract.exe`
  - Langues support√©es: Fran√ßais + Anglais (fra+eng)
  - R√¥le: Extraction du texte brut depuis les images/PDF

#### **Python et Biblioth√®ques**
- **Python 3.x** : Langage de programmation principal
- **pytesseract (v0.3.10)** : Interface Python pour Tesseract OCR
- **pdf2image (v1.16.3)** : Conversion PDF ‚Üí Images pour traitement OCR
- **Pillow (v10.1.0)** : Manipulation d'images (PIL)
- **opencv-python (v4.8.1.78)** : Traitement d'images avanc√©

#### **LLM (Large Language Model)**
- **Ollama** : Plateforme pour ex√©cuter des LLM en local
  - Mod√®le utilis√©: **llama3.2** (par d√©faut)
  - Autres mod√®les support√©s: mistral, etc.
  - R√¥le: Post-traitement intelligent pour correction OCR et structuration

#### **Traitement de Donn√©es**
- **JSON** : Format de sortie structur√©
- **RegEx** : Patterns pour corrections OCR de base
- **argparse** : Interface en ligne de commande

---

## üèóÔ∏è Architecture du Projet

### Structure des Fichiers

```
projet_ocr_fst/
‚îÇ
‚îú‚îÄ‚îÄ ocr_extractor.py          # Script principal (778 lignes)
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                 # Documentation compl√®te
‚îú‚îÄ‚îÄ PRESENTATION_PROJET.md    # Ce document
‚îÇ
‚îú‚îÄ‚îÄ input/                    # Documents sources
‚îÇ   ‚îú‚îÄ‚îÄ CV_Aymen_Ennaji.pdf
‚îÇ   ‚îú‚îÄ‚îÄ modele_de_facture.pdf
‚îÇ   ‚îî‚îÄ‚îÄ rempli.pdf
‚îÇ
‚îî‚îÄ‚îÄ output/                   # R√©sultats g√©n√©r√©s
    ‚îú‚îÄ‚îÄ *_extracted.txt      # Texte brut OCR
    ‚îî‚îÄ‚îÄ *_cleaned.json       # JSON structur√©
```

---

## üîÑ Processus Complet de A √† Z

### **√âtape 1 : Pr√©paration de l'Environnement**

```bash
# 1. Installation de Tesseract OCR (Windows)
#    T√©l√©charg√© depuis: https://github.com/UB-Mannheim/tesseract/wiki
#    Install√© dans: C:\Program Files\Tesseract-OCR\

# 2. Installation d'Ollama
#    T√©l√©charg√© et install√© sur le PC local
#    Mod√®le t√©l√©charg√©: ollama pull llama3.2

# 3. Cr√©ation de l'environnement Python
python -m venv venv
venv\Scripts\activate

# 4. Installation des d√©pendances
pip install -r requirements.txt
```

### **√âtape 2 : Extraction OCR (Texte Brut)**

#### **2.1 Pour les Images (PNG, JPG, etc.)**
```python
def extract_text_from_image(image_path):
    # 1. Ouvrir l'image avec PIL
    image = Image.open(image_path)
    
    # 2. Extraire le texte avec Tesseract OCR
    text = pytesseract.image_to_string(image, lang='fra+eng')
    
    # 3. Retourner le texte brut
    return text
```

#### **2.2 Pour les PDF**
```python
def extract_text_from_pdf(pdf_path):
    # 1. Convertir chaque page PDF en image
    images = convert_from_path(pdf_path)
    
    # 2. Extraire le texte de chaque page avec OCR
    all_text = []
    for image in images:
        text = pytesseract.image_to_string(image, lang='fra+eng')
        all_text.append(text)
    
    # 3. Combiner toutes les pages
    return "\n\n".join(all_text)
```

**R√©sultat:** Fichier `*_extracted.txt` contenant le texte brut OCR (avec erreurs potentielles)

---

### **√âtape 3 : Pr√©-traitement (Corrections de Base)**

```python
def pre_process_ocr_text(text):
    # Corrections automatiques via RegEx
    corrections = {
        'Dipl6m√©' ‚Üí 'Dipl√¥m√©',
        'lnformation' ‚Üí 'Information',
        'Node,js' ‚Üí 'Node.js',
        'Expressjjs' ‚Üí 'Express.js',
        # ... etc
    }
    # Applique les corrections
    return corrected_text
```

**Objectif:** Corriger les erreurs OCR les plus √©videntes avant le LLM

---

### **√âtape 4 : D√©tection Automatique du Type de Document**

```python
def detect_document_type(text):
    # Analyse des mots-cl√©s pour d√©tecter:
    # - CV: curriculum, vitae, comp√©tences, formation
    # - Facture: facture, invoice, TVA, HT, TTC
    # - Formulaire: formulaire, nom, pr√©nom, adresse
    # - General: par d√©faut
    return detected_type
```

**R√©sultat:** Type de document d√©tect√© automatiquement ou sp√©cifi√© par l'utilisateur

---

### **√âtape 5 : Post-traitement Intelligent avec LLM**

#### **5.1 G√©n√©ration du JSON Structur√© (OPTIMIS√â)**

**Nouvelle approche optimis√©e:** Un seul appel LLM qui fait tout en une fois !

```python
def extract_json_from_ocr_text(raw_text, doc_type):
    # 1. Pr√©-traitement avec corrections de base
    pre_processed = pre_process_ocr_text(raw_text)
    
    # 2. G√©n√©ration du prompt adapt√© au type de document
    prompt = get_json_prompt_from_ocr(pre_processed, doc_type)
    #    Ce prompt int√®gre:
    #    - Instructions de correction OCR
    #    - Structure JSON attendue selon le type
    #    - Instructions d'extraction structur√©e
    
    # 3. Appel unique √† Ollama (correction + extraction en une √©tape)
    response = ollama.generate(model='llama3.2', prompt=prompt)
    
    # 4. Extraction et parsing du JSON
    json_data = json.loads(response['response'])
    
    return json_data
```

**Avantages:**
- ‚úÖ **2x plus rapide** : Un seul appel LLM au lieu de deux
- ‚úÖ **Meilleure qualit√©** : Correction et extraction dans la m√™me √©tape
- ‚úÖ **Optimis√©** : Pas d'√©tape interm√©diaire de texte nettoy√©

---

### **√âtape 6 : Structures JSON selon le Type**

#### **Pour les CV:**
```json
{
  "a_propos_de_moi": {
    "nom": "...",
    "titre": "...",
    "telephone": "...",
    "email": "...",
    "github": "...",
    "linkedin": "..."
  },
  "langues": [...],
  "education": [...],
  "experiences_professionnelles": [...],
  "competences_techniques": {...},
  "soft_skills": [...],
  "loisirs": [...]
}
```

#### **Pour les Factures:**
```json
{
  "en_tete": {
    "fournisseur": {...},
    "client": {...}
  },
  "details": {...},
  "articles": [...],
  "totaux": {...}
}
```

#### **Pour les Formulaires:**
```json
{
  "titre": "...",
  "sections": [...],
  "tous_les_champs": [...],
  "signature": {...}
}
```

---

## üîß Fonctionnalit√©s Principales

### 1. **Extraction OCR Multi-format**
- ‚úÖ PDF (multi-pages)
- ‚úÖ Images: PNG, JPG, JPEG, BMP, TIFF

### 2. **Correction Automatique des Erreurs OCR**
- ‚úÖ Correction via RegEx (pr√©-traitement)
- ‚úÖ Correction intelligente via LLM (post-traitement)
- ‚úÖ Exemples de corrections:
  - "Dipl6m√©" ‚Üí "Dipl√¥m√©"
  - "lnformation" ‚Üí "Information"
  - "Node,js" ‚Üí "Node.js"

### 3. **D√©tection Automatique du Type de Document**
- ‚úÖ CV
- ‚úÖ Facture
- ‚úÖ Formulaire
- ‚úÖ G√©n√©ral (d√©tection automatique par mots-cl√©s)

### 4. **Structuration Intelligente**
- ‚úÖ Organisation logique du contenu
- ‚úÖ Conservation de la hi√©rarchie (sections, sous-sections)
- ‚úÖ Extraction des informations cl√©s

### 5. **Export JSON Structur√©**
- ‚úÖ Format JSON standard
- ‚úÖ Structure adapt√©e au type de document
- ‚úÖ Donn√©es pr√™tes pour traitement automatique

---

## üìä Exemple d'Utilisation

### **Commande de base:**
```bash
python ocr_extractor.py input/CV_Aymen_Ennaji.pdf
```

### **Processus automatique:**
1. **OCR** ‚Üí Extraction du texte brut ‚Üí `CV_Aymen_Ennaji_extracted.txt`
2. **D√©tection** ‚Üí Type de document: "cv" (automatique)
3. **LLM** ‚Üí Correction OCR + Extraction JSON (une seule √©tape)
4. **R√©sultat** ‚Üí `CV_Aymen_Ennaji_cleaned.json`

### **Options avanc√©es:**
```bash
# Sp√©cifier le type de document
python ocr_extractor.py facture.pdf --type facture

# Choisir le mod√®le LLM
python ocr_extractor.py document.pdf --model mistral

# D√©sactiver le LLM (OCR uniquement)
python ocr_extractor.py document.pdf --no-llm
```

---

## üéØ R√©sultats Obtenus

### **Avant (OCR brut):**
```
A PROPOS DE MOI
ENNAJI AYMEN
D√©veloppeur Web & Syst√©mes d'lnformation
& 0626424451 & aymenennajiS@gmail.com
lin] linkedin.com/in/aymen-ennaji
LANGUES
Jeune dipl6m√© en D√©veloppement des Systemes d'Information
...
```

### **Apr√®s (JSON structur√©):**
```json
{
  "a_propos_de_moi": {
    "nom": "Ennaji Aymen",
    "titre": "D√©veloppeur Web & Syst√®mes d'Information",
    "telephone": "0626424451",
    "email": "aymenennaji@gmail.com",
    "linkedin": "linkedin.com/in/aymen-ennaji"
  },
  "langues": [
    {"langue": "Fran√ßais", "niveau": "Courant"},
    {"langue": "Anglais", "niveau": "Technique"},
    {"langue": "Arabe", "niveau": "Langue maternelle"}
  ],
  "education": [...],
  "experiences_professionnelles": [...]
}
```

**Corrections automatiques:**
- ‚úÖ "dipl6m√©" ‚Üí "Dipl√¥m√©"
- ‚úÖ "lnformation" ‚Üí "Information"
- ‚úÖ "Systemes" ‚Üí "Syst√®mes"
- ‚úÖ "aymenennajiS" ‚Üí "aymenennaji"
- ‚úÖ "lin]" ‚Üí "linkedin"

---

## ‚ö° Optimisations Impl√©ment√©es

### 1. **Passage Direct OCR ‚Üí JSON**
- **Avant:** OCR ‚Üí Texte nettoy√© ‚Üí JSON (2 appels LLM)
- **Apr√®s:** OCR ‚Üí JSON (1 seul appel LLM)
- **Gain:** 2x plus rapide

### 2. **Pr√©-traitement RegEx**
- Corrections rapides avant le LLM
- R√©duction des erreurs courantes

### 3. **D√©tection Automatique**
- √âvite de sp√©cifier le type manuellement
- Adaptation automatique du traitement

---

## üìà Points Forts du Projet

1. **‚úÖ Extraction OCR pr√©cise** : Support multi-format (PDF, images)
2. **‚úÖ Correction intelligente** : LLM pour corriger les erreurs OCR
3. **‚úÖ Structuration automatique** : Organisation logique du contenu
4. **‚úÖ Export JSON** : Format standard pour traitement automatique
5. **‚úÖ Multi-types de documents** : CV, factures, formulaires, etc.
6. **‚úÖ D√©tection automatique** : Reconnaissance du type de document
7. **‚úÖ Optimisation** : Traitement rapide (un seul appel LLM)
8. **‚úÖ Qualit√©** : Correction et extraction en une √©tape

---

## üî¨ D√©fis Rencontr√©s et Solutions

### **D√©fi 1: Erreurs OCR fr√©quentes**
**Probl√®me:** Caract√®res mal reconnus (6‚Üí√¥, l‚ÜíI, etc.)

**Solution:** 
- Pr√©-traitement RegEx pour corrections rapides
- Post-traitement LLM pour corrections intelligentes

### **D√©fi 2: Structure m√©lang√©e apr√®s OCR**
**Probl√®me:** Sections m√©lang√©es, texte non structur√©

**Solution:**
- Prompts LLM sp√©cifiques par type de document
- Instructions d√©taill√©es pour r√©organisation intelligente

### **D√©fi 3: Temps de traitement long**
**Probl√®me:** 2 appels LLM s√©quentiels (nettoyage + JSON)

**Solution:**
- Optimisation: Un seul appel LLM qui fait correction + extraction
- Gain de temps: 2x plus rapide

---

## üí° Am√©liorations Futures Possibles

1. **Interface graphique** : GUI avec drag & drop
2. **API REST** : Service web pour int√©gration
3. **Traitement par lots** : Traiter plusieurs fichiers en une fois
4. **Support de plus de formats** : Word, Excel, etc.
5. **Apprentissage automatique** : Mod√®le sp√©cifique pour OCR

---

## üìö R√©f√©rences Techniques

- **Tesseract OCR:** https://github.com/tesseract-ocr/tesseract
- **Ollama:** https://ollama.ai/
- **pytesseract:** https://github.com/madmaze/pytesseract
- **pdf2image:** https://github.com/Belval/pdf2image

---

## üìù Conclusion

Ce projet d√©montre l'int√©gration r√©ussie de **technologies OCR** et **LLM** pour cr√©er un syst√®me d'extraction intelligent. 

**Principales r√©alisations:**
- ‚úÖ Syst√®me complet et fonctionnel
- ‚úÖ Support multi-types de documents
- ‚úÖ Correction automatique des erreurs
- ‚úÖ Export structur√© en JSON
- ‚úÖ Optimisations pour performance

**Technologies ma√Ætris√©es:**
- OCR (Tesseract)
- LLM (Ollama)
- Python et biblioth√®ques
- Traitement de documents
- Structuration de donn√©es

