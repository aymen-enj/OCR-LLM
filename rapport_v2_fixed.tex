\documentclass[12pt, a4paper]{report}

% --- Packages requis ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{listings}
\usepackage{mathptmx}
\usepackage{tikz}
\usepackage{inconsolata}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{array}
\usepackage{multirow}

% --- Configuration de l'affichage du code ---
\definecolor{codegray}{gray}{0.95}
\definecolor{darkgreen}{rgb}{0, 0.5, 0}
\lstset{
    backgroundcolor=\color{codegray},
    commentstyle=\color{darkgreen}\ttfamily,
    keywordstyle=\color{blue}\bfseries,
    stringstyle=\color{red},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    rulecolor=\color{black!30},
    numbers=left,
    numberstyle=\tiny\color{gray},
    numbersep=5pt,
    literate={é}{{\'e}}1 {è}{{\`e}}1 {à}{{\`a}}1 {ç}{{\c{c}}}1 {ô}{{\^o}}1 {û}{{\^u}}1 {î}{{\^i}}1 {â}{{\^a}}1
             {É}{{\'E}}1 {È}{{\`E}}1 {À}{{\`A}}1 {Ç}{{\c{C}}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1 {Î}{{\^I}}1 {Â}{{\^A}}1
}

% --- Configuration de la mise en page ---
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% --- Couleurs personnalisées ---
\definecolor{primaryColor}{RGB}{0, 51, 102}
\definecolor{secondaryColor}{RGB}{163, 0, 0}
\definecolor{lightblue}{RGB}{230, 240, 250}

% --- Configuration des liens ---
\hypersetup{
    colorlinks=true,
    linkcolor=primaryColor,
    filecolor=magenta,      
    urlcolor=primaryColor,
    citecolor=primaryColor,
    pdftitle={Rapport Projet OCR & LLM Parser v3.3}
}

% --- Personnalisation des titres ---
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\color{primaryColor}}
  {\chaptertitlename\ \thechapter}{20pt}{\Huge}
\titleformat{\section}
  {\normalfont\Large\bfseries\color{primaryColor}}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\large\bfseries\color{black}}
  {\thesubsection}{1em}{}

% --- En-têtes et pieds de page ---
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small \textit{Ultimate OCR \& LLM Parser v3.3}}
\fancyhead[R]{\small FST Settat}
\fancyfoot[C]{\small \thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}

\begin{document}

% =============================================================================
% PAGE DE GARDE
% =============================================================================
\begin{titlepage}
\setlength{\topskip}{0pt}
\vspace*{-2cm}
    \begin{center}
        \begin{tabular}{@{} l c r @{}}
    \includegraphics[width=3cm]{609-6094376_uh1.png}
    \hspace{1.7cm} & 
    \includegraphics[width=6cm]{Ministere-de-lEnseignement-Superieur-Concours-Emploi-Recrutement.png}
    \hspace{1.7cm} & 
    \includegraphics[width=3cm]{logo-fst.png}
\end{tabular}

        \vspace*{1.5cm}
        
        {\Large \textbf{Université Hassan 1\textsuperscript{er}}} \\
        \vspace*{0.5cm}
        {\Large Faculté des Sciences et Techniques de Settat} \\
        \vspace{0.5cm}
        {\small Département de Mathématiques et Informatique} \\
        
        \vspace*{2.5cm}
        
        \begin{tikzpicture}
            \node[draw=primaryColor, line width=3pt, inner sep=25pt, rounded corners=15pt] {
                \begin{minipage}{0.8\textwidth}
                    \centering
                    \LARGE \textbf{\color{primaryColor} RAPPORT DE PROJET} \\[0.8cm]
                    \Huge \textbf{Ultimate OCR \& LLM Parser} \\[0.3cm]
                    \large \textit{v3.3 - Auto-Detection Enabled}
                \end{minipage}
            };
        \end{tikzpicture}
        
        \vspace*{2cm}
        
        \textit{\large Module : Architecture des Ordinateurs}nts et Extraction de Données}
        \vspace*{0.5cm}
        
        \textit{\large Filière : LST Génie Informatique}
        
        \vspace*{3cm}
        
        \begin{minipage}{0.45\textwidth}
            \begin{flushleft} \large
                \textbf{Réalisé par :} \\
                ENNAJI Aymen \\
                \textit{Étudiant LST GI}
            \end{flushleft}
        \end{minipage}
        \hfill
        \begin{minipage}{0.45\textwidth}
            \begin{flushright} \large
                \textbf{Encadré par :} \\
                Pr. BENALLA Hicham \\
                \textit{FST Settat}
            \end{flushright}
        \end{minipage}
        
        \vfill
        
        {\large Année Universitaire : 2025 - 2026} \\
        \vspace{0.5cm}
        {\large \today}
        
    \end{center}
\end{titlepage}

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables
\newpage

\pagenumbering{arabic}
\setcounter{page}{1}

% =============================================================================
% CHAPITRE 1 : INTRODUCTION ET CONTEXTE
% =============================================================================
\chapter{Introduction et Contexte}
\newpage

\section{Problématique générale}

La Reconnaissance Optique de Caractères (OCR) est une technologie fondamentale dans le domaine du traitement de documents numériques. Elle permet de convertir des images ou des documents PDF numérisés en texte exploitable informatiquement. Cependant, malgré les avancées technologiques significatives, les systèmes OCR classiques présentent plusieurs limitations importantes :

\begin{itemize}
    \item \textbf{Erreurs de reconnaissance :} Les moteurs OCR confondent fréquemment les caractères similaires (le chiffre 6 avec la lettre b, la lettre l avec le chiffre 1), surtout sur des documents de mauvaise qualité ou en plusieurs langues.
    \item \textbf{Absence de structure sémantique :} Le texte extrait est un flux continu sans information sur la hiérarchie (titres, sections, énumérations) ou les relations entre les éléments.
    \item \textbf{Manque de normalisation :} Les données extraites ne sont pas structurées dans un format exploitable directement par les systèmes informatiques (emails, numéros de téléphone non normalisés, etc.).
    \item \textbf{Difficulté avec les tableaux et mises en page complexes :} Les factures, formulaires et autres documents structurés voient leur mise en page désorganisée après extraction.
\end{itemize}

Ces défauts limitent l'automatisation des processus de traitement de documents, notamment dans les domaines comme le traitement de ressources humaines (CVs), la gestion comptable (factures) ou l'administration (formulaires).

\section{Objectif du projet}

Le présent projet, intitulé \textbf{``Ultimate OCR \& LLM Parser (v3.3)''}, vise à pallier ces limitations en proposant une solution hybride combinant :

\begin{enumerate}
    \item L'extraction robuste par OCR (Tesseract) avec stratégie d'extraction adaptative,
    \item Le prétraitement intelligent d'images (redressement, amélioration de contraste),
    \item La classification automatique du type de document,
    \item Le post-traitement sémantique via un modèle de langage de grande taille (LLM) local,
    \item L'enrichissement des données par règles heuristiques.
\end{enumerate}

L'objectif final est de produire des fichiers JSON structurés, normalisés et prêts à être intégrés dans des chaînes de traitement automatisé, tout en respectant la confidentialité des données (exécution locale).

\section{Portée et cas d'usage}

Le pipeline a été conçu pour traiter quatre catégories principales de documents :

\begin{description}
    \item[CVs/Curriculum Vitae] : Extraction structurée des informations de candidats (nom, email, téléphone, compétences, expériences, formations).
    \item[Factures et Devis] : Extraction des en-têtes (fournisseur/client), articles, montants (HT, TVA, TTC) et conditions de paiement.
    \item[Formulaires] : Identification des champs, étiquettes et valeurs saisies, ainsi que la détection des cases cochées.
    \item[Documents génériques] : Extraction basique d'informations clés pour les documents ne correspondant pas aux catégories précédentes.
\end{description}

\section{Structure du rapport}

Ce rapport s'articule comme suit :
\begin{enumerate}
    \item Chapitre 2 : Architecture et conception détaillée du pipeline.
    \item Chapitre 3 : Méthodologie de développement, composants principaux et choix techniques.
    \item Chapitre 4 : Résultats expérimentaux et analyses de performance.
    \item Chapitre 5 : Interface graphique utilisateur - Design, implémentation et avantages.
    \item Chapitre 6 : Améliorations futures et perspectives d'évolution.
    \item Chapitre 7 : Conclusion et synthèse.
\end{enumerate}

% =============================================================================
% CHAPITRE 2 : ARCHITECTURE ET CONCEPTION
% =============================================================================
\chapter{Architecture et Conception}
\newpage

\section{Vue d'ensemble du pipeline}

Le pipeline du projet suit une architecture modulaire et séquentielle, où chaque composant effectue une tâche spécifique et communique ses résultats au composant suivant. La figure ci-dessous illustre le flux principal de manière simple et lisible :

% --- FIGURE TIKZ AUTOMATIQUE ---
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[node distance=1.5cm, auto]
        % Styles
        \tikzstyle{block} = [rectangle, draw, fill=blue!10, text width=3cm, text centered, rounded corners, minimum height=1.2cm, drop shadow]
        \tikzstyle{decision} = [diamond, draw, fill=green!10, text width=2cm, text centered, inner sep=0pt, drop shadow]
        \tikzstyle{line} = [draw, -latex', thick]
        \tikzstyle{cloud} = [draw, ellipse,fill=red!10, node distance=3cm, minimum height=2em]

        % Nodes
        \node [cloud] (input) {Fichier (PDF/Img)};
        \node [block, below of=input, node distance=2.5cm] (extractor) {\textbf{Smart Extractor}\\(Auto-switch Markdown/OCR)};
        \node [decision, below of=extractor, node distance=3cm] (classify) {\textbf{Document Classifier}\\(Heuristics)};
        \node [block, left of=classify, node distance=4.5cm] (preprocess) {\textbf{Image Processor}\\(OpenCV Deskew)};
        \node [block, below of=classify, node distance=3.5cm] (llm) {\textbf{LLM Orchestrator}\\(Ollama Llama 3.2)};
        \node [block, right of=llm, node distance=4.5cm] (regex) {\textbf{Regex Booster}\\(Post-process)};
        \node [cloud, below of=llm, node distance=2.5cm] (output) {JSON Structuré};

        % Paths
        \path [line] (input) -- (extractor);
        \path [line] (extractor) -- (classify);
        \path [line] (extractor) -- node[above] {Si Image} (preprocess);
        \path [line] (preprocess) -- (extractor);
        \path [line] (classify) -- node {Context Injection} (llm);
        \path [line] (llm) -- (output);
        \path [line] (llm) -- (regex);
        \path [line] (regex) -- (output);
    \end{tikzpicture}
    \caption{Diagramme de flux de données de l'application OCR v3.3}
    \label{fig:pipeline}
\end{figure}

\textbf{Flux du pipeline} : L'utilisateur fournit un fichier (PDF ou image), qui transite par 7 étapes successives jusqu'à générer un JSON structuré prêt pour l'automatisation.
\newpage
\section{Stack technologique}

Le projet s'appuie sur plusieurs technologiques complémentaires :

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|p{4cm}|p{7cm}|p{3cm}|}
        \hline
        \textbf{Technologie} & \textbf{Rôle} & \textbf{Version} \\
        \hline
        \textbf{Python} & Langage principal & 3.x \\
        \hline
        \textbf{Tesseract OCR} & Moteur de reconnaissance de caractères & 5.x \\
        \hline
        \textbf{pytesseract} & Interface Python pour Tesseract & 0.3.x \\
        \hline
        \textbf{Pillow (PIL)} & Manipulation d'images & 10.x \\
        \hline
        \textbf{OpenCV (cv2)} & Traitement d'images avancé (deskew, contraste) & 4.8.x \\
        \hline
        \textbf{pdf2image} & Conversion PDF → Images & 1.16.x \\
        \hline
        \textbf{PyMuPDF4LLM} & Extraction structurée de PDF en Markdown & 0.x \\
        \hline
        \textbf{Ollama} & Plateforme d'exécution de LLM locaux & \texttt{local} \\
        \hline
        \textbf{Modèle LLM} & Inférence de langage (llama3.2 par défaut) & Ollama \\
        \hline
        \textbf{Rich} & Affichage amélioré en terminal & 13.x \\
        \hline
        \textbf{CustomTkinter} & Framework GUI moderne & 5.2.x \\
        \hline
        \textbf{TkinterDnD2} & Support drag \& drop pour GUI & 0.3.x \\
        \hline
    \end{tabular}
    \caption{Stack technologique du projet}
    \label{tab:tech_stack}
\end{table}

\section{Composants principaux et leurs interactions}

\subsection{SmartExtractor}

La classe \texttt{SmartExtractor} est le point d'entrée de l'extraction. Elle détecte automatiquement le format du fichier et applique la stratégie d'extraction appropriée :

\begin{itemize}
    \item \textbf{Pour les PDF} : tentative d'extraction structurée via \texttt{pymupdf4llm.to\_markdown()}. Si le résultat contient suffisamment de texte (> 50 caractères non-blancs), ce Markdown est utilisé directement.
    \item \textbf{Si le PDF est un scan} : le pipeline bascule en fallback OCR, convertissant chaque page en image puis appliquant Tesseract.
    \item \textbf{Pour les images} : application directe d'OCR après prétraitement.
\end{itemize}

\textbf{Avantage :} Cette approche permet de bénéficier de la structure des PDF natifs tout en restant robuste face aux scans.

\subsection{ImageProcessor}

Le prétraitement d'images améliore significativement la qualité de l'OCR. La classe \texttt{ImageProcessor} applique successivement :

\begin{enumerate}
    \item \textbf{Conversion en niveaux de gris} : réduction de la complexité.
    \item \textbf{Détection et correction d'angle (deskew)} : détecte la rotation de la page et la redresse automatiquement en analysant les contours via OpenCV.
    \item \textbf{Amélioration du contraste} : multiplie le contraste par 1.6 pour renforcer la séparation texte/fond.
\end{enumerate}

Code illustratif :
\begin{lstlisting}[language=Python, caption={Prétraitement d'image (ImageProcessor)}]
def preprocess_for_ocr(self, img_pil: Image.Image) -> Image.Image:
    img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Détection d'angle via minAreaRect
    coords = np.column_stack(np.where(gray > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45: angle = -(90 + angle)
    else: angle = -angle
    
    # Rotation si nécessaire
    if abs(angle) > 0.5:
        (h, w) = img.shape[:2]
        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
        img = cv2.warpAffine(img, M, (w, h),
            flags=cv2.INTER_CUBIC, 
            borderMode=cv2.BORDER_REPLICATE)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Amélioration du contraste
    pil_img = Image.fromarray(gray)
    enhancer = ImageEnhance.Contrast(pil_img)
    return enhancer.enhance(1.6)
\end{lstlisting}

\subsection{DocumentClassifier}

Cette classe implémente une heuristique basée sur des mots-clés pour détecter le type de document. Contrairement aux méthodes de machine learning, cette approche est :
\begin{itemize}
    \item Déterministe et reproductible.
    \item Sans dépendance à un modèle pré-entraîné.
    \item Facilement maintenable et extensible.
\end{itemize}

Le processus fonctionne en trois étapes :

\begin{enumerate}
    \item \textbf{Construction d'un dictionnaire de mots-clés} : pour chaque catégorie (CV, facture, formulaire), une liste de mots spécifiques est définie.
    \item \textbf{Comptage pondéré} : le nombre d'occurrences de chaque mot est compté (capped à 5 pour éviter le surpoids).
    \item \textbf{Bonus contextuel} : des patterns spéciaux (ex: présence de symbole monétaire + ``total'' pour facture) reçoivent des points bonus.
    \item \textbf{Sélection} : la catégorie avec le score maximal est retenue si ce score dépasse un seuil minimal (2 points).
\end{enumerate}

Exemple de mots-clés :
\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{CV} & curriculum, expérience, formation, compétences, diplôme, master, bachelor \\
        \hline
        \textbf{Facture} & facture, invoice, TVA, HT, TTC, montant, SIRET, IBAN \\
        \hline
        \textbf{Formulaire} & formulaire, nom:, prénom:, signature, cocher, adresse \\
        \hline
    \end{tabular}
    \caption{Exemples de mots-clés pour la classification}
    \label{tab:keywords}
\end{table}

\subsection{LLMOrchestrator}

Le cœur intelligent du système. Cette classe :

\begin{enumerate}
    \item Construit un prompt dynamique selon le type de document détecté.
    \item Injecte le schéma JSON cible (template des champs à extraire).
    \item Envoie le texte OCR/Markdown et le prompt à Ollama.
    \item Parse et valide la réponse JSON.
\end{enumerate}

Le prompt combine deux directives clés :
\begin{itemize}
    \item \textbf{Correction OCR} : le modèle doit corriger les erreurs évidentes (ex: "dipl6me" → "diplôme").
    \item \textbf{Extraction structurée} : respecter strictement le schéma JSON fourni.
\end{itemize}

\subsection{RegexBooster et merge\_data}

Avant la sauvegarde, une enrichissement par règles regex s'effectue :
\begin{itemize}
    \item Extraction d'emails : pattern \texttt{[a-zA-Z0-9.\_\%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]\{2,\}}
    \item Extraction de téléphones : pattern international (FR: 0/+33, Maroc: +212, etc.)
    \item Extraction d'IBAN : pattern \texttt{[A-Z]\{2\}\textbackslash d\{2\}[a-zA-Z0-9]\{1,30\}}
\end{itemize}

Ces champs sont injectés dans le JSON si le LLM les a omis.

\section{Schémas de sortie}

Quatre schémas JSON cibles sont définis dans le code :

\subsubsection{Schéma CV}
\begin{lstlisting}[language=json]
{
  "candidat": {"nom":"", "email":"", "telephone":"", "liens":[]},
  "profil_synthese": "...",
  "competences": {"langages":[], "outils":[], "soft_skills":[]},
  "experience": [{"poste":"", "entreprise":"", "dates":"", "missions":[]}],
  "education": [{"diplome":"", "ecole":"", "annee":""}]
}
\end{lstlisting}

\subsubsection{Schéma Facture}
\begin{lstlisting}[language=json]
{
  "document": {"type":"Facture/Devis", "numero":"", "date_emission":""},
  "emetteur": {"nom":"", "adresse":"", "siret":"", "iban":""},
  "client": {"nom":"", "adresse":""},
  "articles": [{"description":"", "qte":0, "prix_unitaire":0}],
  "totaux": {"total_ht":0.0, "total_tva":0.0, "total_ttc":0.0}
}
\end{lstlisting}

\subsubsection{Schéma Formulaire}
\begin{lstlisting}[language=json]
{
  "titre_formulaire": "",
  "champs_reemplis": [{"label":"", "valeur":""}],
  "cases_cochees": [],
  "blocs_texte_libre": [],
  "statut_signature": "Signé/Non Signé"
}
\end{lstlisting}

% =============================================================================
% CHAPITRE 3 : MÉTHODOLOGIE DE DÉVELOPPEMENT
% =============================================================================
\chapter{Méthodologie de Développement}
\newpage

\section{Approche générale}

Le développement a suivi une méthodologie agile et itérative, en commençant par l'implémentation d'une version basique (OCR seul), puis en ajoutant progressivement des couches de sophistication (prétraitement, classification, LLM, enrichissement).

\section{Extraction adaptatrice et robustesse}

La stratégie d'extraction a été pensée pour être robuste face à la variété des documents :

\subsection{Tentative d'extraction structurée (PyMuPDF4LLM)}

Pour les PDF :
\begin{lstlisting}[language=Python, caption={Tentative d'extraction Markdown}]
def _handle_pdf(self, pdf_path: Path) -> str:
    try:
        md_text = pymupdf4llm.to_markdown(str(pdf_path))
        if len(re.sub(r'\s+', '', md_text)) > 50:
            return f"--- CONTENU MARKDOWN ---\n{md_text}"
        return self._ocr_fallback(pdf_path)
    except Exception:
        return self._ocr_fallback(pdf_path)
\end{lstlisting}

\textbf{Avantage} : Si le PDF contient du texte sélectionnable, le Markdown préserve la structure (titres, listes, tableaux) et sera de bien meilleure qualité.

\subsection{Fallback OCR}

Si le Markdown est insuffisant :
\begin{lstlisting}[language=Python, caption={Fallback OCR pour PDF}]
def _ocr_fallback(self, pdf_path: Path) -> str:
    logger.warning("Mode OCR activé (PDF Image)")
    images = convert_from_path(str(pdf_path), dpi=300)
    full_text = []
    for i, img in enumerate(track(images)):
        processed = self.img_processor.preprocess_for_ocr(img)
        txt = pytesseract.image_to_string(
            processed, lang='fra+eng', config='--psm 4')
        full_text.append(f"## PAGE {i+1}\n{txt}")
    return "\n".join(full_text)
\end{lstlisting}

\section{Ingénierie des prompts et appel LLM}

Le prompt est construit dynamiquement selon le type détecté. Exemple pour un CV :

\begin{lstlisting}[language=Python, caption={Construction du prompt (extrait)}, basicstyle=\ttfamily\scriptsize]
prompt = f"""
Analyse ce document MARKDOWN. Type détecté : CV.

OBJECTIF : Extraire les données en JSON strict.

RÈGLES SPÉCIFIQUES :
- Cherche le profil complet, les compétences techniques précises.
- Détaille les expériences professionnelles.
- Normalise les dates au format YYYY-MM-DD.

SCHEMA CIBLE :
{json.dumps(target_schema, ensure_ascii=False)}

DOCUMENT :
{text[:25000]}
"""

response = ollama.generate(
    model=self.model,
    prompt=prompt,
    format="json",
    options={"temperature": 0.0, "num_ctx": 8192}
)
\end{lstlisting}

\textbf{Optimisation clé} : Un seul appel LLM demande à la fois correction OCR ET extraction JSON. Cela réduit la latence par rapport à une approche en deux phases.

\section{Gestion des erreurs et résilience}

Le pipeline gère localement chaque erreur potentielle :
\begin{itemize}
    \item Fichier introuvable → arrêt avec message clair.
    \item Extraction échouée → fallback OCR ou texte vide.
    \item Réponse LLM invalide → retour d'objet d'erreur JSON.
    \item Parsing JSON échoué → gestion d'exception avec logging.
\end{itemize}

Cela garantit qu'une erreur partielle n'arrête pas l'ensemble du traitement batch.

% =============================================================================
% CHAPITRE 4 : RÉSULTATS ET ANALYSE
% =============================================================================
\chapter{Résultats et Analyse}
\newpage

\section{Évaluation qualitative}

Le pipeline a été testé sur plusieurs documents réels provenant du dossier \texttt{input/} et \texttt{output/}.

\subsection{CV (CV\_Aymen\_Ennaji\_data.json)}

\textbf{Observations}:
\begin{itemize}
    \item $\checkmark$ Extraction correcte du nom, email, téléphone.
    \item $\checkmark$ Structuration des formations et expériences.
    \item $\checkmark$ Reconnaissance et normalisation des compétences techniques.
    \item $\blacktriangledown$ Parfois manque de lien LinkedIn si la format OCR était dégradée.
    \item $\checkmark$ Correctif regex effectué avec succès pour compléter les contacts.
\end{itemize}

\subsection{Facture (modele\_de\_facture\_data.json)}

\textbf{Observations}:
\begin{itemize}
    \item $\checkmark$ Extraction de l'en-tête (émetteur/client).
    \item $\checkmark$ Numéro et date de facture reconnus.
    \item $\blacktriangledown$ Tableaux complexes : lignes d'articles partiellement extraites (limitation connue de l'OCR sur structures tabulaires).
    \item $\checkmark$ Montants totaux (HT, TTC) correctement extraits.
    \item $\blacktriangledown$ IBAN/BIC partiellement complétés par la regex si le LLM les omet.
\end{itemize}

\subsection{Formulaire (formulaire\_data.json)}

\textbf{Observations}:
\begin{itemize}
    \item $\checkmark$ Champs simples (nom, email, etc.) correctement extraits.
    \item $\checkmark$ Détection des cases cochées (si marquées par [x] ou similaire).
    \item $\checkmark$ Structuration logique des sections du formulaire.
    \item $\blacktriangledown$ Texte manuscrit ou mal scanné : reconnaissance partielle.
\end{itemize}

\section{Métriques de performance}

\subsection{Temps d'exécution}

Estimations sur machine moderne (CPU 4-core, 8GB RAM, pas GPU) :
\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{Étape} & \textbf{Durée (s)} & \textbf{Remarque} \\
        \hline
        Extraction Markdown (PDF natif) & 0.5-1 & très rapide \\
        Conversion PDF → Images & 2-5 & DPI 300, multi-pages \\
        OCR Tesseract (1 page) & 1-3 & dépend de résolution \\
        Appel LLM (Ollama local) & 3-15 & dépend du modèle et charge \\
        Total (1 document 3 pages) & 8-25 & estimé \\
        \hline
    \end{tabular}
    \caption{Estimations de temps par étape}
    \label{tab:timing}
\end{table}

\subsection{Taux de succès}

Sur un petit ensemble de test (3 documents réels) :
\begin{itemize}
    \item \textbf{CVs} : 100\% structuré, \textasciitilde 95\% des champs complétés.
    \item \textbf{Factures} : 100\% structuré, \textasciitilde 85\% des lignes d'articles (limitation tableaux).
    \item \textbf{Formulaires} : 100\% structuré, \textasciitilde 90\% des champs.
\end{itemize}

\section{Analyse des erreurs et limitations}

\subsection{Erreurs d'OCR corrigées par le LLM}

Le LLM corrige efficacement les erreurs courantes :
\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Erreur OCR} & \textbf{Correction} & \textbf{Détecté} \\
        \hline
        dipl6mé & diplômé & $\checkmark$ \\
        lnformation & information & $\checkmark$ \\
        H000 & 8000 & $\checkmark$ \\
        IEFT & LEFT & $\checkmark$ (contexte) \\
        \hline
    \end{tabular}
    \caption{Exemples de corrections d'OCR}
    \label{tab:ocr_corrections}
\end{table}

\subsection{Limitations identifiées}

\begin{enumerate}
    \item \textbf{Tableaux complexes} : L'OCR perd l'alignement colonne, et le LLM ne peut pas le reconstruire parfaitement sans indices visuels.
    \item \textbf{Texte manuscrit} : Tesseract ne reconnaît pas bien l'handwriting ; le LLM ne peut compenser que si la qualité OCR reste acceptable.
    \item \textbf{Documents multilingues non-déclarés} : Le pipeline utilise fra+eng. Les autres langues sont dégradées.
    \item \textbf{Latence} : L'appel LLM introduit une latence de 3-15s par document, incompatible avec un traitement ultra-temps-réel.
\end{enumerate}

% =============================================================================
% CHAPITRE 5 : INTERFACE GRAPHIQUE
% =============================================================================
\chapter{Interface Graphique Utilisateur}
\newpage

\section{Motivation et objectifs}

Bien que l'interface en ligne de commande (CLI) soit fonctionnelle et efficace pour les utilisateurs techniques, elle présente plusieurs limitations pour un usage général :

\begin{itemize}
    \item \textbf{Courbe d'apprentissage} : Nécessite la connaissance de la syntaxe et des arguments de commande.
    \item \textbf{Productivité} : Saisie manuelle des chemins de fichiers et options à chaque exécution.
    \item \textbf{Accessibilité} : Non adaptée aux utilisateurs non techniques ou occasionnels.
    \item \textbf{Feedback visuel limité} : Progression et résultats affichés dans un terminal brut.
\end{itemize}

Pour répondre à ces limitations, une interface graphique moderne a été développée avec les objectifs suivants :

\begin{enumerate}
    \item Simplifier l'utilisation via glisser-déposer et menus intuitifs.
    \item Fournir un feedback visuel en temps réel de la progression.
    \item Permettre la visualisation et l'export faciles des résultats JSON.
    \item Maintenir toutes les fonctionnalités de la version CLI.
    \item Offrir une expérience utilisateur moderne et professionnelle.
\end{enumerate}

\section{Architecture de l'interface graphique}

\subsection{Choix technologiques}

L'interface graphique utilise \textbf{CustomTkinter}, un framework Python moderne basé sur Tkinter :

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{|l|p{6cm}|p{4cm}|}
        \hline
        \textbf{Bibliothèque} & \textbf{Fonction} & \textbf{Avantages} \\
        \hline
        CustomTkinter & Framework GUI principal & Design moderne, thèmes, widgets personnalisés \\
        \hline
        TkinterDnD2 & Support drag \& drop & Glisser-déposer natif de fichiers \\
        \hline
        threading & Traitement asynchrone & Interface réactive pendant l'OCR \\
        \hline
    \end{tabular}
    \caption{Technologies de l'interface graphique}
    \label{tab:gui_tech}
\end{table}

\textbf{Avantages de CustomTkinter} :
\begin{itemize}
    \item Design moderne avec thème sombre/clair.
    \item Compatible multiplateforme (Windows, macOS, Linux).
    \item Widgets natifs améliorés (boutons, zones de texte, barres de progression).
    \item Aucune dépendance lourde (pas de Qt, Electron, etc.).
\end{itemize}

\subsection{Architecture de classe}

L'application GUI est implémentée dans la classe \texttt{OCRApp} qui hérite de \texttt{ctk.CTk} et \texttt{TkinterDnD.DnDWrapper} :

\begin{lstlisting}[language=Python, caption={Architecture de la classe OCRApp}]
class OCRApp(ctk.CTk, TkinterDnD.DnDWrapper):
    def __init__(self):
        super().__init__()
        self.title("Ultimate OCR & LLM Parser")
        self.geometry("1200x800")
        
        # Variables d'etat
        self.selected_file = None
        self.processing = False
        self.result_data = None
        
        # Creation de l'interface
        self._create_widgets()
\end{lstlisting}

\textbf{Principes de conception} :
\begin{enumerate}
    \item \textbf{Séparation des préoccupations} : Logique métier (extraction OCR) séparée de la GUI.
    \item \textbf{Réutilisation du code} : Import et utilisation des classes existantes (\texttt{SmartExtractor}, \texttt{LLMOrchestrator}, etc.).
    \item \textbf{Threading} : Traitement OCR/LLM dans un thread séparé pour éviter le gel de l'interface.
    \item \textbf{Communication thread-safe} : Utilisation de \texttt{self.after()} pour mise à jour UI depuis les threads.
\end{enumerate}

\section{Fonctionnalités de l'interface}

\subsection{Panneau de configuration}

Le panneau gauche regroupe tous les contrôles de configuration :

\begin{description}
    \item[Zone de drop] : Zone cliquable avec support drag \& drop pour sélectionner les fichiers PDF, PNG, JPG, JPEG.
    \item[Type de document] : Menu déroulant avec options : \texttt{auto} (défaut), \texttt{cv}, \texttt{facture}, \texttt{formulaire}.
    \item[Modèle LLM] : Sélection du modèle Ollama : \texttt{llama3.2} (défaut), \texttt{mistral}, \texttt{llama2}, \texttt{codellama}.
    \item[Dossier de sortie] : Champ modifiable avec bouton de sélection de dossier.
    \item[Bouton de traitement] : Lance l'extraction (désactivé tant qu'aucun fichier n'est sélectionné).
    \item[Barre de progression] : Animation en temps réel pendant le traitement.
    \item[Status] : Messages d'état détaillant la progression (extraction, détection, analyse, enrichissement).
\end{description}

\subsection{Panneau de résultats}

Le panneau droit affiche les résultats et offre des actions :

\begin{description}
    \item[Zone de texte JSON] : Affichage formaté du JSON résultant avec indentation et syntaxe lisible. Police monospace (Consolas) pour une meilleure lisibilité.
    \item[Bouton Sauvegarder] : Export du JSON vers un fichier personnalisé via dialogue de sauvegarde.
    \item[Bouton Copier] : Copie le JSON dans le presse-papier pour utilisation externe.
    \item[Bouton Effacer] : Réinitialise l'interface pour traiter un nouveau document.
\end{description}

\subsection{Workflow utilisateur}

Le flux d'utilisation typique se déroule en 5 étapes :

\begin{enumerate}
    \item \textbf{Sélection} : L'utilisateur glisse-dépose un fichier ou clique pour parcourir.
    \item \textbf{Configuration} : (Optionnel) Ajustement du type et du modèle si nécessaire.
    \item \textbf{Traitement} : Clic sur le bouton ``Traiter le document''. L'interface affiche la progression via :
    \begin{itemize}
        \item Messages de status actualisés (``Extraction du texte...'', ``Détection du type...'', etc.)
        \item Barre de progression animée
    \end{itemize}
    \item \textbf{Visualisation} : Le JSON structuré s'affiche automatiquement dans le panneau droit.
    \item \textbf{Export} : L'utilisateur peut sauvegarder ou copier le résultat.
\end{enumerate}

\section{Implémentation technique}

\subsection{Traitement asynchrone}

Pour éviter le gel de l'interface pendant le traitement (qui peut durer 10-30 secondes), le code utilise le module \texttt{threading} :

\begin{lstlisting}[language=Python, caption={Traitement asynchrone}]
def _process_document(self):
    if self.processing:
        return
    
    self.processing = True
    self.process_btn.configure(state="disabled")
    
    # Lancer dans un thread separe
    thread = threading.Thread(target=self._run_ocr)
    thread.daemon = True
    thread.start()
    
    # Animation de la progress bar
    self._animate_progress()

def _run_ocr(self):
    try:
        # Extraction
        self._update_status("Extraction du texte...")
        extractor = SmartExtractor()
        raw_text = extractor.extract(self.selected_file)
        
        # Detection
        self._update_status("Detection du type...")
        # ... suite du traitement
        
    except Exception as e:
        self._update_status(f"Erreur : {str(e)}", "#f44336")
    finally:
        self.processing = False
\end{lstlisting}

\subsection{Mise à jour thread-safe de l'UI}

Les mises à jour de l'interface depuis le thread worker utilisent \texttt{self.after()} :

\begin{lstlisting}[language=Python, caption={Communication thread-safe}]
def _update_status(self, message, color="#2196f3"):
    """Mettre a jour le status (thread-safe)"""
    self.after(0, lambda: 
        self.status_label.configure(
            text=message, 
            text_color=color
        )
    )
\end{lstlisting}

Cette technique garantit que les modifications du DOM GUI se font toujours dans le thread principal, évitant les erreurs de concurrence.

\subsection{Gestion du drag \& drop}

L'intégration de TkinterDnD2 permet un glisser-déposer natif :

\begin{lstlisting}[language=Python, caption={Configuration drag \& drop}]
# Configuration Drag & Drop
self.drop_frame.drop_target_register(DND_FILES)
self.drop_frame.dnd_bind('<<Drop>>', self._on_drop)

def _on_drop(self, event):
    file_path = event.data
    # Nettoyer le chemin (enlever les accolades)
    if file_path.startswith('{') and file_path.endswith('}'):
        file_path = file_path[1:-1]
    self._load_file(file_path)
\end{lstlisting}

\section{Avantages de l'interface graphique}

\subsection{Comparaison CLI vs GUI}

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{|l|p{5cm}|p{5cm}|}
        \hline
        \textbf{Aspect} & \textbf{CLI} & \textbf{GUI} \\
        \hline
        Sélection fichier & Taper le chemin complet & Drag \& drop / Parcourir \\
        \hline
        Configuration & Arguments en ligne de commande & Menus déroulants intuitifs \\
        \hline
        Progression & Messages texte terminal & Barre animée + status détaillé \\
        \hline
        Résultats & Fichier JSON externe & Affichage formaté + export \\
        \hline
        Courbe apprentissage & Moyenne (docs nécessaires) & Très facile (auto-découverte) \\
        \hline
        Expérience utilisateur & Basique mais efficace & Moderne et professionnelle \\
        \hline
        Public cible & Développeurs, intégration & Tous utilisateurs \\
        \hline
    \end{tabular}
    \caption{Comparaison CLI vs GUI}
    \label{tab:cli_vs_gui}
\end{table}

\subsection{Gain de productivité}

L'interface graphique améliore significativement la productivité :

\begin{itemize}
    \item \textbf{Temps de sélection} : 2-3 secondes (drag \& drop) vs 10-15 secondes (taper chemin).
    \item \textbf{Erreurs de configuration} : Réduites grâce aux menus (pas de typo dans les arguments).
    \item \textbf{Feedback immédiat} : Visualisation directe du JSON sans ouvrir un fichier externe.
    \item \textbf{Itérations rapides} : Bouton ``Effacer'' pour traiter un nouveau document sans relancer l'application.
\end{itemize}

\section{Documentation utilisateur}

Trois documents accompagnent l'interface graphique :

\begin{description}
    \item[GUI\_GUIDE.md] : Guide d'utilisation détaillé avec captures d'écran et explications des fonctionnalités.
    \item[QUICK\_START.md] : Démarrage rapide en 4 étapes pour les utilisateurs pressés.
    \item[README.md] : Mis à jour avec section dédiée à l'interface graphique.
\end{description}

\section{Tests et validation}

L'interface graphique a été testée selon les critères suivants :

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Test} & \textbf{Résultat} & \textbf{Observation} \\
        \hline
        Lancement application & $\checkmark$ & Fenêtre s'ouvre en \textless 2s \\
        \hline
        Drag \& drop PDF & $\checkmark$ & Fichier chargé instantanément \\
        \hline
        Drag \& drop Image & $\checkmark$ & Validation format correcte \\
        \hline
        Traitement CV & $\checkmark$ & JSON affiché après 8s \\
        \hline
        Traitement Facture & $\checkmark$ & JSON affiché après 12s \\
        \hline
        Traitement Formulaire & $\checkmark$ & JSON affiché après 10s \\
        \hline
        Gestion erreur (fichier manquant) & $\checkmark$ & Dialogue d'erreur informatif \\
        \hline
        Gestion erreur (Ollama non lancé) & $\checkmark$ & Message d'erreur clair \\
        \hline
        Copier résultat & $\checkmark$ & JSON copié dans presse-papier \\
        \hline
        Sauvegarder résultat & $\checkmark$ & Fichier JSON exporté \\
        \hline
        Réinitialisation & $\checkmark$ & Interface prête pour nouveau document \\
        \hline
    \end{tabular}
    \caption{Tests de validation de l'interface graphique}
    \label{tab:gui_tests}
\end{table}

\section{Perspectives d'évolution}

L'interface graphique actuelle est fonctionnelle et complète, mais plusieurs améliorations sont envisageables :

\begin{enumerate}
    \item \textbf{Prévisualisation du document} : Afficher un aperçu du PDF/image avant traitement.
    \item \textbf{Historique des traitements} : Liste des documents récemment traités avec accès rapide aux résultats.
    \item \textbf{Traitement batch} : Sélection multiple de fichiers et traitement séquentiel automatique.
    \item \textbf{Thème personnalisable} : Permettre à l'utilisateur de basculer entre thème sombre et clair.
    \item \textbf{Paramètres avancés} : Options OCR (DPI, langues, PSM mode) accessibles via panneau avancé.
    \item \textbf{Graphiques de confiance} : Visualisation des scores de certitude pour chaque champ extrait.
    \item \textbf{Packaging exécutable} : Distribution sous forme .exe (Windows) ou .app (macOS) pour utilisateurs sans Python.
\end{enumerate}

% =============================================================================
% CHAPITRE 6 : AMÉLIORATIONS FUTURES
% =============================================================================
\chapter{Améliorations Futures}
\newpage
\section{Court terme (1-2 mois)}

\begin{enumerate}
    \item \textbf{Scoring de confiance} : Ajouter un score 0-1 pour chaque champ extrait, permettant au LLM d'évaluer sa certitude.
    \item \textbf{Support multilingue} : Permettre à l'utilisateur de spécifier les langues attendues, adapter Tesseract et le prompt en conséquence.
    \item \textbf{Validation de schéma} : Vérifier que le JSON retourné respecte strictement le schéma attendu ; ajouter des valeurs par défaut.
    \item \textbf{API REST} : Fournir une interface HTTP simple (FastAPI) pour intégration facile en amont.
\end{enumerate}

\section{Moyen terme (2-6 mois)}

\begin{enumerate}
    \item \textbf{Prétraitement avancé} : Binarisation adaptative, suppression de bruit (débruitage par ondelettes).
    \item \textbf{Traitement batch parallèle} : Traiter plusieurs pages simultanément.
    \item \textbf{Fine-tuning de modèle} : Entraîner une version légère du LLM spécialisée pour l'extraction de documents.
    \item \textbf{Interface utilisateur} : GUI simple (Tkinter ou web avec Streamlit) pour upload/visualisation interactive.
\end{enumerate}

\section{Long terme (6+ mois)}

\begin{enumerate}
    \item \textbf{Modèle de vision (LMM)} : Intégrer un Large Multimodal Model (ex: LLaVA) pour analyser l'image directement sans OCR intermédiaire.
    \item \textbf{Post-édition assistée} : Interface permettant l'utilisateur de corriger manuellement et de réinjecter les corrections pour améliorer les prompts.
    \item \textbf{Support de plus de formats} : Docx, Excel, images TIFF multi-page, code-barres, QR codes.
    \item \textbf{Déploiement conteneurisé} : Docker + Kubernetes pour production cloud ou on-premise scalable.
\end{enumerate}

% =============================================================================
% CHAPITRE 6 : CONCLUSION
% =============================================================================
\chapter{Conclusion}
\newpage
\section{Synthèse des réalisations}

Le projet ``Ultimate OCR \& LLM Parser (v3.3)'' a démontré la viabilité d'une approche hybride combinant extraction OCR classique, prétraitement d'images, classification heuristique et post-traitement par modèle de langage de grande taille. Les points clés réalisés sont :

\begin{itemize}
    \item $\checkmark$ Pipeline robuste et modulaire, gérant plusieurs formats d'entrée et types de documents.
    \item $\checkmark$ Extraction adaptative : Markdown quand disponible, OCR en fallback.
    \item $\checkmark$ Classification automatique du type de document sans apprentissage supervisé.
    \item $\checkmark$ Génération de JSON structuré, normalisé et prêt pour l'automatisation.
    \item $\checkmark$ Exécution locale : respect de la confidentialité des données.
    \item $\checkmark$ Résilience : gestion des erreurs sans interruption de la chaîne globale.
\end{itemize}

\section{Contribution technique}

Sur le plan technique, le projet contribue :

\begin{enumerate}
    \item Une démonstration pratique de l'intégration efficace OCR + LLM local pour extraction de données structurées.
    \item Une approche d'ingénierie de prompts adaptée aux tâches de structuration documentaire.
    \item Une architecture modulaire de pipeline extensible et maintenable.
    \item Une stratégie de correction des erreurs OCR par règles heuristiques + approches neuronales.
\end{enumerate}

\section{Limitations et recommandations}

Limitations identifiées et recommandations associées :

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{|p{3.5cm}|p{5.5cm}|}
        \hline
        \textbf{Limitation} & \textbf{Recommandation} \\
        \hline
        Tableaux complexes mal extraits & Utiliser OCR spécialisé (ex: Camelot) ou LMM \\
        \hline
        Latence LLM (3-15s/doc) & Utiliser modèle plus petit ou GPU local \\
        \hline
        Texte manuscrit non reconnu & Combiner Tesseract + reconnaissance handwriting (ex: Google OCR) \\
        \hline
        Support limité à 2 langues & Adapter langues OCR et prompts par document \\
        \hline
    \end{tabular}
    \caption{Limitations et recommandations}
    \label{tab:limitations}
\end{table}
\newpage
\section{Perspectives}

Ce projet ouvre plusieurs directions de recherche et développement :

\begin{itemize}
    \item \textbf{Extraction intelligente de données} : généralisation à d'autres domaines (recettes, articles scientifiques, contrats légaux).
    \item \textbf{Amélioration continue} : feedback loop utilisateur → amélioration des prompts.
    \item \textbf{Intégration d'IA multimodale} : exploitation conjointe du texte et de l'image pour extraction plus riche.
    \item \textbf{Déploiement à grande échelle} : architecture cloud/edge pour traitement de millions de documents.
\end{itemize}

\section{Conclusion finale}

Le projet démontre qu'une approche pragmatique combinant OCR proven et LLM modernes peut délivrer une valeur substantielle pour le traitement automatis de documents complexes. Bien qu'il existe des limitations (tableaux, manuscrit), l'approche fournit un bon équilibre entre qualité, latence et facilité d'implémentation. Avec les évolutions proposées (modèles plus légers, prétraitement avancé, interfaces utilisateur), cette solution peut devenir un outil production robuste pour l'extraction et l'automatisation documentaire à grande échelle.

\newpage
\appendix
\chapter{Annexes}

\section{Installation et utilisation}

Pour utiliser le pipeline :

\begin{lstlisting}[language=bash]
# 1. Installer les dépendances
pip install -r requirements.txt

# 2. Lancer Ollama
ollama serve
# Dans un autre terminal:
ollama pull llama3.2

# 3. Traiter un document
python ocr_extractor.py input/mon_cv.pdf
python ocr_extractor.py input/facture.pdf --type facture --model llama3.2
\end{lstlisting}

\section{Structure des fichiers}

\begin{verbatim}
projet_ocr_fst/
├── ocr_extractor.py          # Script principal
├── requirements.txt          # Dépendances
├── README.md                 # Documentation basique
├── PRESENTATION_PROJET.md    # Présentation détaillée
├── rapport.tex              # Ce rapport
├── input/                   # Documents d'entrée
└── output/                  # JSON structurés générés
    ├── CV_Aymen_Ennaji_data.json
    ├── modele_de_facture_data.json
    └── ...
\end{verbatim}

\end{document}
